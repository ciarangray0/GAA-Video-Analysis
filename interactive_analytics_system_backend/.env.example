# GPU Inference Configuration
#
# Options for GPU_PROVIDER:
#   - modal: Use Modal serverless GPU (recommended)
#   - runpod: Use RunPod serverless GPU
#   - local: Use local CPU (slow, requires torch dependencies)

# Modal Configuration
GPU_PROVIDER=modal
GPU_ENDPOINT_URL=https://your-username--gaa-yolo-tracking-yolotracker-track-video-endpoint.modal.run

# RunPod Configuration (if using RunPod instead)
# GPU_PROVIDER=runpod
# GPU_ENDPOINT_URL=https://api.runpod.ai/v2/your-endpoint-id/run
# GPU_API_KEY=your-runpod-api-key

# Local CPU fallback (for testing only - very slow)
# GPU_PROVIDER=local

